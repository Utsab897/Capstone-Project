# -*- coding: utf-8 -*-
"""creditcard_fraud_dectection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NFFqzVznhVv6I_YWsKD2uUEgBnMu0uLJ

# **Credit Card Fraud Detection Model**
"""

#Importing nessary libaries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt



import warnings
warnings.filterwarnings('ignore')

"""# **Loading the Dataset**"""

data =pd.read_csv('/content/creditcard (1).csv')

data.head()

data.shape

print(data.info())

"""# 	**Exploratory Data Analysis (EDA)**"""

#Checking for Null values
data.isnull().sum()

# Finding the distribution of class
print(data['Class'].value_counts())


print('No Frauds', round(data['Class'].value_counts()[0]/len(data) * 100,2), '% of the dataset')
print('Frauds', round(data['Class'].value_counts()[1]/len(data) * 100,2), '% of the dataset')

sns.countplot(x='Class',data = data)
plt.title('Class Distributions \n (0: No Fraud || 1: Fraud)', fontsize=14)

# Separating the Fraud & Non Fraud transaction

fraud = data[data['Class']==1]

normal = data[data['Class']==0]

# How different are the amount of money used in different transaction classes?
fraud.Amount.describe()

normal.Amount.describe()

f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)
f.suptitle('Amount per transaction by class')
bins = 50
ax1.hist(fraud.Amount, bins = bins)
ax1.set_title('Fraud')
ax2.hist(normal.Amount, bins = bins)
ax2.set_title('Normal')
plt.xlabel('Amount($)')
plt.ylabel('No. of Transactions')
plt.xlim((0, 20000))
plt.yscale('log')
plt.show();

fig, (axis_1, axis_2) = plt.subplots(2, 1, sharex=True, figsize=(12,4))
fig.suptitle('Time compared to Number of transactions according to transaction classes')
bins = 50
axis_1.hist(data.Time[data.Class == 1], bins = bins)
axis_1.set_title('Fraud')
axis_2.hist(data.Time[data.Class == 0], bins = bins)
axis_2.set_title('Normal (Non-Fraud)')
plt.xlabel('Time (in Seconds)')
plt.ylabel('Number of Transactions')
plt.show()

# Comparing the time for both classes of transsaction
plt.figure(figsize=(8, 5))
ax = sns.distplot(fraud['Time'], label='fradulent', hist=False)
ax = sns.distplot(normal['Time'], label='non_fraudulent', hist=False)
ax.set(xlabel='Time elapsed between the transction ')
plt.legend(loc='best')
plt.show()

# plotting correlations on a heatmap

corr = data.corr()
plt.figure(figsize=(20,20))
sns.heatmap(corr, annot=True, cmap='rocket_r')

"""# **Standard Scaling**"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
data['Amount']=sc.fit_transform(pd.DataFrame(data['Amount']))
data['Time']=sc.fit_transform(pd.DataFrame(data['Time']))

"""
# **Input Split**"""

X = data.drop('Class',axis=1)
y = data['Class']

X.shape

y.shape

y.value_counts()

"""# **Checking For Skewness**"""

cols = X.columns
cols

k=0
plt.figure(figsize=(12, 20))
for col in cols:
  k=k+1
  plt.subplot(6, 5, k)
  sns.distplot(X[col])
  plt.tight_layout()
  plt.title(col + ' --> ' + str(round(X[col].skew(), 3)))

# Handling Skewness with Power Transformer
# Importing PowerTransformer
from sklearn.preprocessing import PowerTransformer
pt = PowerTransformer(method='yeo-johnson', standardize=True, copy=False)
X[cols] = pt.fit_transform(X)

"""



# **Train test split**"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,
                                                 random_state=42,stratify=y)

"""# **Balancing the Data by Oversampling using SMOTE**"""

from imblearn.over_sampling import SMOTE

X_rs,y_rs = SMOTE().fit_resample(X_train,y_train)

y_rs.value_counts()

"""# **Model Training**"""

# Creating KFold object with 5 splits
from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV

folds = KFold(n_splits=5, shuffle=True, random_state=4)

# Specify params
params = {"C": [0.01, 0.1, 1, 10, 100, 1000]}

from sklearn.linear_model import LogisticRegression
model_cv = GridSearchCV(estimator = LogisticRegression(),
                        param_grid = params,
                        scoring= 'roc_auc',
                        cv = folds,
                        verbose = 1,
                        return_train_score=True)

# Fit the model
model_cv.fit(X_rs, y_rs)

print(model_cv.best_score_)
print(model_cv.best_params_['C'])

# Hyperparameter Tunning
# Tunning model with best C
lr = LogisticRegression(C=1000)

logistic_model = lr.fit(X_rs, y_rs)

# Predictions on the test set
y_test_pred = logistic_model.predict(X_test)

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,roc_auc_score

print("Accuracy:-", accuracy_score(y_test, y_test_pred))
print("ROC AUC:", roc_auc_score(y_test, y_test_pred))

confusion=confusion_matrix(y_test, y_test_pred)
sns.heatmap(confusion, annot=True)

print(classification_report(y_test, y_test_pred))

# Predictions on the train set
y_train_pred = logistic_model.predict(X_rs)

print("Accuracy:-", accuracy_score(y_rs, y_train_pred))
print("ROC AUC:", roc_auc_score(y_rs, y_train_pred))

confusion1=confusion_matrix(y_rs, y_train_pred)
sns.heatmap(confusion1, annot=True)

print(classification_report(y_rs, y_train_pred))

"""The models performed well with Logistic regression  and has ROC score 0.95 in the train set and 0.94 on the test set.And accuracy of 95% and 97% respectively.




"""